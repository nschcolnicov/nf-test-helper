# Nextflow Test Generator

1. Run the nextflow pipeline with the test profile for which you want to generate an nf-test.
2. Run the `nf-test-gen.py` to initialize the nf-test for all of the files found in the output directory. This will output a `.nf.test` file.
3. Then nf-test test on the generated `.nf.test` file redirecting stdout and stdout to a new file. i.e `nf-test test tests/test.nf.test > nf-test.out 2>&1`.
4. Run the `snap_out_checker.py` to generate a table that will contain a table with the comparsion of the md5sums of all the files used in the snapshot.
5. Finally run `test_updater.py` to update the generated `.nf.test` file replacing the md5sum check with only a `.exists()` assertion for undeterministic files.
6. Loop around steps 3 to 5 until the nf-test.out file contains no mismatching md5sums.


## nf-test-gen.py

This script, `nf-test-gen.py`, automates the creation of `nf-test` files for testing Nextflow pipelines. It recursively scans the provided output directory (`$outputDir`) to generate snapshot assertions based on the files found. The script ensures that only relevant files are included in the assertions by excluding specific file types such as `.json`, `.html`, `.log`, `.png`, `.svg`, and `.pdf`.

The generated `nf-test` files can then be used to validate the correctness of your Nextflow pipeline by checking that the expected output files are produced and match the snapshots.

## Usage

To generate an `nf-test` file using the `nf-test-gen.py` script, follow these steps:

### 1. Command-Line Execution

Run the script from the command line with the following syntax:

```bash
python nf-test-gen.py <outputDir> <test_name> <number_of_tasks>
```

### Arguments

- **`<outputDir>`**: The path to the directory containing the output files from your Nextflow pipeline. The script will traverse this directory and generate snapshot assertions based on the files found within the first-level subdirectories. It skips files with the extensions `.json`, `.html`, `.log`, `.png`, `.svg`, and `.pdf`, as well as the `pipeline_info` directory.

- **`<test_name>`**: A string that will be used as the name of the test case in the generated `nf-test` file. This name will also be used for tagging the test and identifying it in the `nf-test` output.

- **`<number_of_tasks>`**: An integer that represents the expected number of successfully completed tasks in the Nextflow workflow. This value will be used to assert that the correct number of tasks succeeded.

### Output
The script generates a working `.nf.test` file for validating a nextflow pipeline execution.

## snap_out_checker.py

`snap_out_checker.py` is a utility script designed to process the output of nf-test executions by extracting and comparing the MD5 checksums of files used in snapshots. The script generates a summary table in CSV format, which indicates whether the checksums match between pairs of files. This tool is especially useful for validating the reproducibility and consistency of outputs generated by Nextflow pipelines.

## Usage
To use the snap_out_checker.py script, follow these steps:

Run the nf-test command on the generated .nf.test file and redirect the output to a file (e.g., nf-test.out).
Execute snap_out_checker.py to process the output file and generate a CSV report.
```bash
python snap_out_checker.py <input_file>
```

### Arguments

- **`<input_file>`**: The path to the input file generated by the nf-test execution (e.g., nf-test.out). The script will parse this file, extract relevant lines containing MD5 checksums, compare them, and produce an output CSV file (`output.csv`) summarizing the results.

### Output
The script generates an `output.csv` file containing the following columns:

- **`<test_name>`**: The name of the test workflow, extracted from the input file.
- **`<file1>`**: The first file involved in the MD5 comparison.
- **`<md5_1>`**: The MD5 checksum of the first file.
- **`<file2>`**: The second file involved in the MD5 comparison.
- **`<md5_2>`**: The MD5 checksum of the second file.
- **`<Match>`**: Indicates whether the MD5 checksums match (YES or NO).
This CSV file provides a clear overview of which files have consistent checksums, aiding in debugging and ensuring the correctness of your pipeline outputs.

## `test_updater.py`

`test_updater.py` is a script designed to refine the `.nf.test` files generated for testing Nextflow pipelines. It updates assertions for undeterministic files by replacing their MD5 checksum checks with `.exists()` assertions. This allows for more flexible testing when output files may vary slightly between runs, but their presence is still expected.

#### Usage
To use the `test_updater.py` script, follow these steps:

1. Run the `snap_out_checker.py` to generate a CSV file (`output.csv`) that contains the results of MD5 checksum comparisons.
2. Execute `test_updater.py` to update the `.nf.test` file based on the discrepancies found.

```bash
python test_updater.py <csv_file> <nf_test_file>
```

### Arguments

- **`<csv_file>`**: The path to the CSV file generated by snap_out_checker.py. This file contains the comparison results, identifying which files failed the MD5 checksum comparison and need to have their assertions updated.

- **`<nf_test_file>`**: The path to the .nf.test file that you want to update. The script will generate a new version of this file with the .v2 extension, where the MD5 checksum checks for undeterministic files are replaced with .exists() assertions.

### Output
The script produces an updated .nf.test file with the same name as the original but with a .v2 extension. This updated file includes .exists() assertions for files that did not pass the MD5 checksum comparison, allowing for more consistent and flexible testing of your Nextflow pipeline outputs.
